I. 공분산과 상관계수

1. 양의 상관관계(Positively correlated) : 변수 x가 증가할 때 y도 증가
2. 음의 상관관계(Negatively correlated) : 변수 x가 증가할 때 y는 감소
3. 상관관계 없음(Uncorrelated) : 변수 x의 움직임과 y의 움직임이 상관 없음

[특징]
1) 만약 x, y가 독립이라면 공분산은 0
   E[x*y] = E[x]*E[y] 이기 때문에   E[x*y] - E[x]*E[y] = 0 이 성립한다.

2) 단, 공분산은 x와 y의 크기에 영향을 받기 때문에 상관성은 낮지만 절대적 점수가 높은 공분산이 반대의 경우보가 높게 나올 수 있으음

3) 위의 문제 때문에 상관계수로 공분산의 단점을 보완함(-1 <= p <= 1)
  <피어슨의 상관계수>
  0.9 ~ 0.6 : 강한 상관간계
  0.6 ~ 0.3 : 양의 상관관계
  0.3 ~ 0.1 : 상관관계가 있음



II. 상관관계와 인과관계
- 두 변수가 상관관계가 있다고 해서 반드시 인과관계가 있다는 것은 아니다.
  ex) 초콜릿을 많이 먹는 나라일 수록 노벨상 수상자가 많다는 상관관계가 있다고 하더라도,
     이는 초콜릿을 많이 먹는 유럽국가가 노벨상을 많이 받기 때문일 뿐, 초콜릿과 노벨상 간의 인과관계가 있는 것은 아니다.
- 상관관계는 두 변수 사이에서 보여지는 상관성만 나타내는 것
- 인과관계란 x 때문에 y가 발생하는 것
- 회귀분석을 통해 인과관계의 방향, 정도와 수학적 모델을 확인할 수 있음



III. 차원축소(비지도학습의 종류 중 하나. 3차원을 2차원으로 변환)
- 3차원에서의 x축과 y축을 2차원으로 가져와 Pc1, Pc2 와 같은 새로운 특징으로 나타냄

[ 차원축소를 하는 이유는 ]
  - 사람이 보기에 시각적으로 용이함
  - 변수(피처=xyz)의 조합을 통해 새로운 변수(ex. Pc1,Pc2)를 발견할 수 있음
  - 변수의 수를 줄임으로써 "차원의 저주"(차원, 즉 데이터 특징이 많아져서 이를 채우기 위한 데이터의 수도 많아야 함.
    많지 않으면 오버피팅 문제가 발생함)를 보완할 수 있음

[ 차원축소를 하는 방법 ]
1. Feature Selection (변수선택)
  - 가지고 있는 변수(피처)들 중에 의미있는 변수만 선택
  - 변수를 선택하는 방법은 주로 상관분석을 이용

2. Feature Extravtion (변수추출)
  - 1, 2, 3번 변수를 조합하여 A, B라는 변수를 생성
  - 주로 사용되는 방법은 주성분분석(PCA, Principal Component Analysis)
  - PCA 실행 결과로 나온 Variances를 그래프로 그린 뒤 급격하게 떨어지는 지점에서 PC개수 선택
  [ PCA를 하는 방법 ]
  ① 분산이 최대인 축을 찾아서 데이터를 몰아줌 -> 해당 축을 Pc1이라고 부름
  ② 찾은 축과 직교하면서 분산이 최대인 두 번째 축 찾기
  ③ 첫 번째 축과 두 번째 축에 직교하고 분산을 보존하는 세 번째 축 찾기

3. 정규화
  - x와 y의 퍼진 정도(스케일)가 다를 때 서로 맞춰줌
  - PCA를 위해서는 반드시 정규화가 필요함
  - 스케일이 다르면 분산이 다름