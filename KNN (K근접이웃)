KNN (K 근접이웃)

프로세스
1. 가장 가깐운 K개의 점을 찾는다. (K는 마음대로 설정 가능)
2. K개의 점 중 A가 많은지 B가 많은지 확인한다.
3. 많은 범주 쪽으로 분류한다.

K를 정할 때 주의할 점
- K는 너무 적으면 안 된다. K가 너무 작으면 노이즈에 민감한 과적합의 우려가 있다.
    (highly locally sensitive)
- K가 너무 크면 지역적 구조를 파악하는 능력을 잃는다.
    (lose the ability to capture the local structure)
- 적절한 K값을 찾아내는 것이 우수한 K-인접이웃 모델을 만드는데 필수적인 요소다.
- 검증 데이터에 대한 에러가 가장 낮은 K값을 선택해야한다.

K(참조할 이웃의 수) 결정하기
1. 가지고 있는 데이터를 둘로 나눈다.(Train(학습) 데이터, Test(검증) 데이터)
2. Train(학습) 데이터에서 학습된 데이터로 Test(검증) 데이터를 예측해본다.
    이때, k의 개수마다 kNN 모델을 한 번씩 다 학습시킨다.
3. 만들어진 Test(검증) 데이터에서 K의 개수에 따른 에러율을 확인한다.
4. 에러율이 가장 작은 k가 최적의 k다.